안녕하십니까 교수님 15팀(17학번 최재원, 18학번 김준석)입니다.

제작환경은 'Mac os'이고 Elasticsearch의 버전은 7.7.1, Python은 버전 3 입니다.   

저희 팀은 요구기능 1), 2), 3), 4)를 모두 구현하였습니다.

먼저 저희가 올린 파일을 다운 받으신 후, 터미널 창에 ./tp.sh 를 입력하여 쉘 스크립트 파일을 실행 시킵니다.

이 sh 파일 안에는 프로젝트에 필요한 모듈 자동설치한 후, team_project.py 를 실행시킵니다.

저희 팀은 python 파일 하나에 크롤링, Elasticsearch 저장, 분석 프로그램을 구현하였습니다.

team_project.py가 실행되면 http://127.0.0.1:5000/ 을 크롬 주소창에 입력하여 Homepage로 이동합니다.

Homepage에는 단일 url을 입력할수 있는 텍스트 박스, 분석 버튼이 있고,

다중 url이 들어있는 txt파일을 입력받을 수 있는 파일선택 버튼, 분석을 위한 제출 버튼이 있습니다.

단일 텍스트 박스에 url을 입력하여 엔터키를 누르거나 Analyze 버튼을 누르면 /url_status로 이동하여

url의 주소, 크롤링 성공여부, 단어의 수, 그리고 소요시간이 표로 출력됩니다.

그리고 그 페이지에서 Go Home 버튼을 누르게 되면 다시 Homepage로 이동하게 됩니다.

Homepage로 돌아와서 파일 선택 버튼을 눌러 입력할 txt파일을 선택한 후 제출 버튼을 누르면 /file_status로 이동하게됩니다.

그곳에는 중복된 url을 제외한 url 주소, 크롤링 성공여부, 단어수, 중복여부, 소요시간이 표로 출력 됩니다.

표 밑에 TF-IDF 버튼, Cosine-Similarity 버튼, Go Home 버튼이 있습니다.

TF-IDF 버튼을 누르면 /tf_idf 창이 새로 열리며 TF-IDF 기반 상위 top10 주요 단어 리스트를 보여줍니다.

Cosine-Similarity 버튼을 누르면 새로운 창이 열리며 cosine similarity 기반 현재 url 과 가장 유사한 top3 url 리스트를 보여줍니다.

Go Home 버튼을 누르면 원래 있던 Homepage로 돌아가게 됩니다.

저희팀은 크롤링을 한 후, 중복된 url을 제거하고 필요한 정보만을 Elasticsearch에 저장하면서 분석 할 때에 꺼내쓰는 형식으로 구현하였습니다.

감사합니다.


